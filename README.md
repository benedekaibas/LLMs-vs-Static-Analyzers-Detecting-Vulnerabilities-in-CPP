# A Comparative Study on Detecting Vulnerabilities in C++

This research explores how large language models (LLMs) compare to traditional static analyzers in detecting vulnerabilities in C/C++ code. While static analyzers like Clang and Infer provide systematic, rule-based bug detection, they often suffer from false positives and limited coverage of complex patterns. LLMs, on the other hand, bring flexible reasoning and context awareness but may lack precision and consistency.

By evaluating both approaches on benchmark datasets of common C/C++ vulnerabilities (e.g., buffer overflows, null dereferences, memory leaks), this study highlights their strengths, weaknesses, and potential for hybrid use. The goal is to provide insight into whether LLMs can complement or even rival static analysis tools in real-world software security.
